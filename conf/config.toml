# Main configuration for the MyMonitor application.

# ===================================================================
# Monitor-wide settings, now organized into sub-sections.
# ===================================================================
[monitor.general]
# A list of parallelism levels (-j values) to run if none are specified on the command line.
default_jobs = [4, 8, 16]
# If True, plot generation will be skipped after the monitoring run.
skip_plots = false
# The root directory where all run logs and plots will be saved.
log_root_dir = "logs"
# The maximum number of unique command lines to cache for process categorization.
# A larger size may use more memory but can improve performance on extremely
# complex builds with a huge variety of commands. Default is 4096.
categorization_cache_size = 4096

[monitor.collection]
# The time in seconds between each memory sample. Can be a float.
interval_seconds = 0.05
# The type of memory metric to collect ('pss_psutil' or 'rss_pidstat').
metric_type = "pss_psutil"
# Defines the scanning mode for the pss_psutil collector.
# - "full_scan": (Default, Safe) Scans all system processes that match the
#   project's process_pattern. This is robust but can be slow.
# - "descendants_only": (Fast, Experimental) Only scans the descendants of the
#   main build process. This is much faster but may miss processes if the build
#   system spawns them in a detached way. Use the `verify_process_tree.py`
#   tool to check if this mode is safe for your project.
pss_collector_mode = "full_scan"
# Interval for process checking operations (seconds)
process_check_interval = 0.1
# Timeout for monitoring operations (seconds)
monitoring_timeout = 30.0
# Timeout for graceful shutdown (seconds)
graceful_shutdown_timeout = 5.0

[monitor.scheduling]
# Defines the overall CPU scheduling strategy.
# - "adaptive": (Recommended) Automatically allocates CPU cores for build and
#               monitoring tasks based on the build's parallelism (-j value)
#               and total available system cores. It prioritizes isolating
#               the build process and uses remaining cores for monitoring.
# - "manual":   Allows for precise, manual control over core allocation using
#               the 'manual_*' settings below. Use this for fine-tuning or
#               on complex, non-standard system architectures.
scheduling_policy = "adaptive"

# The CPU core to pin the main monitor script and collectors to.
# Used by both 'adaptive' and 'manual' policies.
monitor_core = 0

# --- Settings for 'manual' scheduling_policy ---
# A string defining specific cores for the build (e.g., '1,2,4-7').
manual_build_cores = ""

# A string defining specific cores for monitoring workers (e.g., '8-15').
manual_monitoring_cores = ""

# Enable CPU affinity for monitoring threads (used by ThreadPoolManager)
enable_cpu_affinity = true

# Maximum number of concurrent monitors/workers
max_concurrent_monitors = 8

# Thread/worker name prefix for identification in logs and debugging
thread_name_prefix = "MonitorWorker"

# ===================================================================
# 混合监控架构配置
# 基于生产者-消费者模式的高性能监控设置
# MyMonitor 使用混合架构作为唯一的监控模式
# ===================================================================
[monitor.hybrid]
# Discovery worker scan interval in seconds (how often to scan for new processes)
# Lower values provide better process coverage but use more CPU
hybrid_discovery_interval = 0.01

# Number of sampling workers for parallel memory collection
# More workers can handle higher process loads but use more resources
hybrid_sampling_workers = 4

# Task queue size (number of pending sampling tasks)
# Larger queues can handle bursts but use more memory
hybrid_task_queue_size = 1000

# Result queue size (number of completed samples waiting for processing)
# Should be larger than task queue to avoid blocking sampling workers
hybrid_result_queue_size = 2000

# Enable task prioritization (compiler processes get higher priority)
hybrid_enable_prioritization = true

# Maximum retry count for failed operations
hybrid_max_retry_count = 3

# Queue operation timeout in seconds (how long to wait for queue operations)
hybrid_queue_timeout = 0.1

# Worker operation timeout in seconds (maximum time for worker operations)
hybrid_worker_timeout = 5.0

# Enable queue monitoring for performance analysis
hybrid_enable_queue_monitoring = true

# Batch size for result processing (number of results to process at once)
hybrid_batch_result_size = 50

[monitor.storage]
# Data storage format: "parquet" (recommended) or "json"
# Parquet provides 75-80% space savings and faster query performance
format = "parquet"
# Compression algorithm for Parquet files: "snappy" (default), "gzip", "brotli", "lz4", "zstd"
# Snappy provides good balance between compression ratio and speed
compression = "snappy"
# Whether to generate legacy CSV/JSON formats for backward compatibility
# Set to true if you need to access data with tools that don't support Parquet
generate_legacy_formats = false


# ===================================================================
# Paths to specialized configuration files
# ===================================================================
[paths]
projects_config = "projects.toml"
rules_config = "rules.toml"
