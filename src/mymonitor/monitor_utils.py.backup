"""
Utility functions for monitoring build processes.

This module provides functionalities to:
- Stream output from subprocesses.
- Categorize processes based on their command names and arguments.
- Execute shell commands and capture their output.
- Run and monitor a build process, collecting memory usage data using specified collectors.
- Check for the installation of necessary tools (e.g., pidstat).
- Clean up any running subprocesses upon script termination.
"""

import json
import logging
import os
import polars as pl
import psutil
import re
import subprocess
import threading
import time
from dataclasses import dataclass
from pathlib import Path
from typing import (
    Dict,
    Any,
    Tuple,
    Optional,
    IO,
    List,
)

# Import collectors
from .memory_collectors.base import AbstractMemoryCollector
from .memory_collectors.rss_pidstat_collector import RssPidstatCollector
from .memory_collectors.pss_psutil_collector import PssPsutilCollector


logger = logging.getLogger(__name__)

# --- Module Globals ---
current_build_proc: Optional[subprocess.Popen] = None
"""Global variable to hold the currently running build subprocess. Used for cleanup."""

active_memory_collector: Optional[AbstractMemoryCollector] = None
"""Global variable for the currently active memory collector instance. Used for cleanup."""

_CATEGORY_RULES: Optional[List[Dict[str, Any]]] = None
_RULES_FILE_PATH = Path(__file__).resolve().parent / "category_rules.json"


def _determine_build_cpu_affinity(
    build_cpu_cores_policy: str,
    specific_build_cores_str: Optional[str],
    monitor_core_id: Optional[int],
    taskset_available: bool,
    total_cores_available: Optional[int],
) -> Tuple[str, str]:
    """
    Determines the build command prefix for CPU affinity and a descriptive string.

    Args:
        build_cpu_cores_policy: Policy for assigning CPU cores.
        specific_build_cores_str: String specifying CPU cores for 'specific' policy.
        monitor_core_id: The CPU core ID used by the monitor, to be avoided.
        taskset_available: Boolean indicating if taskset command is available.
        total_cores_available: Total number of CPU cores available on the system.

    Returns:
        A tuple containing:
            - build_command_prefix (str): The prefix for the build command (e.g., "taskset -c ... ").
            - build_cores_target_str (str): A descriptive string of the CPU core targeting.
    """
    build_command_prefix = ""
    build_cores_target_str = "All Available (taskset not used or policy is 'none')"

    if taskset_available and build_cpu_cores_policy != "none":
        cores_for_build_taskset_str: Optional[str] = None
        if build_cpu_cores_policy == "all_others":
            if total_cores_available and total_cores_available > 0:
                if monitor_core_id is not None and total_cores_available > 1:
                    # Exclude the monitor_core_id
                    other_cores = [
                        str(c)
                        for c in range(total_cores_available)
                        if c != monitor_core_id
                    ]
                    if other_cores:
                        cores_for_build_taskset_str = ",".join(other_cores)
                        build_cores_target_str = f"All Other Cores (excluding monitor core {monitor_core_id})"
                    else:  # Only one core available, and it's the monitor core
                        build_cores_target_str = (
                            "All Available (only one core, used by monitor)"
                        )
                else:  # No monitor core to exclude or only one core total
                    cores_for_build_taskset_str = f"0-{total_cores_available - 1}"
                    build_cores_target_str = "All Available Cores"
            else:  # Could not determine total_cores or it's zero
                build_cores_target_str = "All Available (core count unknown)"

        elif build_cpu_cores_policy == "specific":
            if specific_build_cores_str and re.match(
                r"^\d+(-\d+)?(,\d+(-\d+)?)*$", specific_build_cores_str
            ):
                cores_for_build_taskset_str = specific_build_cores_str
                build_cores_target_str = (
                    f"Specific (cores: {cores_for_build_taskset_str})"
                )
            else:
                logger.warning(
                    f"Invalid or missing specific_build_cores ('{specific_build_cores_str}') for 'specific' policy. Build will use all available cores via taskset if possible, or no affinity."
                )
                # Fallback to all available if specific string is bad but taskset is on
                if total_cores_available and total_cores_available > 0:
                    cores_for_build_taskset_str = f"0-{total_cores_available - 1}"
                    build_cores_target_str = (
                        "All Available (invalid specific_build_cores)"
                    )
                else:
                    build_cores_target_str = "All Available (core count unknown, invalid specific_build_cores)"

        if cores_for_build_taskset_str:
            build_command_prefix = f"taskset -c {cores_for_build_taskset_str} "
            logger.info(
                f"Build processes will attempt to run on CPU cores: {cores_for_build_taskset_str} using taskset."
            )
    elif (
        build_cpu_cores_policy != "none"
    ):  # taskset not available but policy is not 'none'
        build_cores_target_str = "All Available (taskset not available)"

    return build_command_prefix, build_cores_target_str


def _prepare_actual_clean_command(
    setup_command_template: Optional[str], clean_command_template: str
) -> Tuple[str, Optional[str]]:
    """
    Prepares the actual clean command string and the executable shell if needed.

    Args:
        setup_command_template: The setup command template, if any.
        clean_command_template: The clean command template.

    Returns:
        A tuple containing:
            - actual_clean_cmd (str): The fully formed clean command.
            - executable_shell (Optional[str]): The shell to use (e.g., "/bin/bash")
                                                 if setup_command is present, otherwise None.
    """
    executable_shell: Optional[str] = None
    actual_clean_cmd: str
    if setup_command_template:
        actual_clean_cmd = f"{setup_command_template} && {clean_command_template}"
        executable_shell = "/bin/bash"  # Assume bash for combined commands
    else:
        actual_clean_cmd = clean_command_template
    return actual_clean_cmd, executable_shell


def _load_category_rules() -> List[Dict[str, Any]]:
    """Loads and caches category rules from the JSON file, sorted by priority."""
    global _CATEGORY_RULES
    if _CATEGORY_RULES is None:
        try:
            with open(_RULES_FILE_PATH, "r") as f:
                rules_data = json.load(f)
            # Sort by priority (descending), then by original order for tie-breaking (implicit)
            _CATEGORY_RULES = sorted(
                rules_data, key=lambda r: r.get("priority", 0), reverse=True
            )
            logger.info(
                f"Successfully loaded {len(_CATEGORY_RULES)} category rules from {_RULES_FILE_PATH}"
            )
        except FileNotFoundError:
            logger.error(f"Category rules file not found: {_RULES_FILE_PATH}")
            _CATEGORY_RULES = []
        except json.JSONDecodeError as e:
            logger.error(f"Error decoding JSON from {_RULES_FILE_PATH}: {e}")
            _CATEGORY_RULES = []
        except Exception as e:
            logger.error(
                f"Failed to load category rules from {_RULES_FILE_PATH}: {e}",
                exc_info=True,
            )
            _CATEGORY_RULES = []  # Default to empty list on error
    return _CATEGORY_RULES


def _stream_output(
    pipe: Optional[IO[str]], prefix: str, output_lines_list: List[str]
) -> None:
    """
    从子进程管道读取行，用给定前缀记录它们，
    并将它们收集到一个列表中。

    This function is designed to be run in a separate thread to allow
    non-blocking reading of a subprocess's stdout or stderr.

    Args:
        pipe: The I/O pipe (e.g., process.stdout) to read from.
              If None, the function returns immediately.
        prefix: A string prefix to prepend to each logged line (e.g., "[STDOUT]").
    """
    if not pipe:
        return
    try:
        # 使用 iter 和 readline 是从管道读取行的常见模式
        for raw_line_content in iter(pipe.readline, ""):
            if not raw_line_content:  # iter 的哨兵应该处理这个问题，但为了安全起见
                break
            stripped_line = raw_line_content.strip()
            logger.debug(f"{prefix}{stripped_line}")
            output_lines_list.append(stripped_line)
    except ValueError:  # 如果管道突然关闭，可能会发生这种情况。
        logger.debug(f"{prefix}Pipe closed or other ValueError during streaming.")
    except Exception as e:
        logger.error(f"{prefix}Unexpected error in _stream_output: {e}", exc_info=True)
    finally:
        if pipe and not pipe.closed:
            try:
                pipe.close()
            except Exception:  # nosec B110
                pass  # 关闭时忽略错误，管道可能已经消失


def _start_stream_reader_thread(
    pipe: Optional[IO[str]],
    stream_name: str,
    project_name: str,
    parallelism_level: int,
    output_list: List[str],
) -> Optional[threading.Thread]:
    """
    Creates and starts a daemon thread to read from a subprocess stream.

    Args:
        pipe: The stream pipe (e.g., subprocess.stdout) to read from.
        stream_name: The name of the stream ("STDOUT" or "STDERR") for logging.
        project_name: The name of the project for the log prefix.
        parallelism_level: The parallelism level for the log prefix.
        output_list: The list to which the stream's lines will be appended.

    Returns:
        The started Thread object if the pipe exists, otherwise None.
    """
    if not pipe:
        return None

    log_prefix = f"[{project_name}-j{parallelism_level} {stream_name}] "

    thread = threading.Thread(
        target=_stream_output,
        args=(pipe, log_prefix, output_list),
        daemon=True,
    )
    thread.start()
    return thread


def _write_stream_to_summary(
    f_handle: IO[Any], stream_name: str, lines: List[str]
) -> None:
    """
    Writes a list of lines from a stream (e.g., stdout, stderr) to the summary log file.

    Args:
        f_handle: The file handle for the summary log.
        stream_name: The name of the stream (e.g., "STDOUT", "STDERR").
        lines: The list of lines to write.
    """
    if lines:
        f_handle.write(f"\n--- Build Process {stream_name} ---\n")
        for line in lines:
            f_handle.write(line + "\n")
        f_handle.write(f"--- End Build Process {stream_name} ---\n")


def get_process_category(cmd_name: str, cmd_full: str) -> Tuple[str, str]:
    """
    Categorizes a process based on its command name and full command line
    using rules defined in category_rules.json.
    Returns a tuple of (major_category, minor_category).
    """
    rules = _load_category_rules()

    orig_cmd_name = cmd_name
    orig_cmd_full = cmd_full

    unwrapped_cmd_name = orig_cmd_name
    unwrapped_cmd_full = orig_cmd_full
    was_sh_bash_c_call = False

    # --- Attempt to unwrap commands executed via sh -c "..." or bash -c "..." ---
    sh_bash_c_pattern = r"^(?:.*/)?(sh|bash)\s+-c\s+"
    is_sh_bash_c_match = re.match(sh_bash_c_pattern, orig_cmd_full)

    if is_sh_bash_c_match:
        was_sh_bash_c_call = True
        command_part = orig_cmd_full[is_sh_bash_c_match.end() :]
        if (command_part.startswith('"') and command_part.endswith('"')) or (
            command_part.startswith("'") and command_part.endswith("'")
        ):
            command_part = command_part[1:-1]

        processed_command_part = re.sub(
            r"^((?:export\s+)?[A-Za-z_][A-Za-z0-9_]*=(?:'[^']*'|\"[^\"]*\"|[^\"'\s]+)\s+)*",
            "",
            command_part.strip(),
        )

        if processed_command_part:
            parts = processed_command_part.split(maxsplit=1)
            if parts:
                potential_new_cmd_name_full_path = parts[0]
                if potential_new_cmd_name_full_path and not "=" in os.path.basename(
                    potential_new_cmd_name_full_path
                ):
                    unwrapped_cmd_name = os.path.basename(
                        potential_new_cmd_name_full_path
                    )
                    unwrapped_cmd_full = processed_command_part

    # --- Normalize .real suffix ---
    current_cmd_name = unwrapped_cmd_name
    if current_cmd_name.endswith(".real"):
        current_cmd_name = current_cmd_name[:-5]
    current_cmd_full = unwrapped_cmd_full

    # --- Apply rules ---
    for rule in rules:
        minor_category_from_rule = rule.get("category")
        major_category_from_rule = rule.get("major_category")
        match_field_key = rule.get("match_field")
        match_type = rule.get("match_type")
        pattern_str = rule.get("pattern")  # Renamed to avoid conflict with re.pattern
        patterns_list = rule.get("patterns")  # Renamed to avoid conflict

        if (
            not minor_category_from_rule
            or not major_category_from_rule
            or not match_field_key
            or not match_type
        ):
            logger.warning(
                f"Skipping invalid rule (missing mandatory fields major_category, category, match_field, or match_type): {rule}"
            )
            continue

        target_value = None
        if match_field_key == "current_cmd_name":
            target_value = current_cmd_name
        elif match_field_key == "current_cmd_full":
            target_value = current_cmd_full
        elif match_field_key == "orig_cmd_name":
            target_value = orig_cmd_name
        elif match_field_key == "orig_cmd_full":
            target_value = orig_cmd_full
        elif match_field_key == "unwrapped_cmd_name":
            target_value = unwrapped_cmd_name
        elif match_field_key == "unwrapped_cmd_full":
            target_value = unwrapped_cmd_full
        else:
            logger.warning(f"Unknown match_field '{match_field_key}' in rule: {rule}")
            continue

        if target_value is None:
            continue

        match_found = False
        if match_type == "exact":
            if pattern_str is not None and target_value == pattern_str:
                match_found = True
        elif match_type == "contains":
            if pattern_str is not None and pattern_str in target_value:
                match_found = True
        elif match_type == "startswith":
            if pattern_str is not None and target_value.startswith(pattern_str):
                match_found = True
        elif match_type == "endswith":
            if pattern_str is not None and target_value.endswith(pattern_str):
                match_found = True
        elif match_type == "regex":
            if pattern_str is not None and re.search(pattern_str, target_value):
                match_found = True
        elif match_type == "in_list":
            if patterns_list is not None and target_value in patterns_list:
                match_found = True
        else:
            logger.warning(f"Unknown match_type '{match_type}' in rule: {rule}")
            continue

        # Special handling for 'ShellInteractiveOrDirect'
        if (
            major_category_from_rule == "Scripting"
            and minor_category_from_rule == "ShellInteractiveOrDirect"
            and was_sh_bash_c_call
        ):
            match_found = False

        if match_found:
            return (
                major_category_from_rule,
                minor_category_from_rule,
            )

    # --- Default category if no rule matches ---
    safe_cmd_name_part = re.sub(r"[^a-zA-Z0-9_.-]", "_", current_cmd_name[:30])
    return "Other", f"Other_{safe_cmd_name_part}"


def run_command(
    command: str, cwd: Path, shell: bool = False, executable_shell: Optional[str] = None
) -> Tuple[int, str, str]:
    """
    Executes a given shell command and returns its exit code, stdout, and stderr.

    Args:
        command: The command string to execute.
        cwd: The working directory in which to run the command.
        shell: If True, the command is executed through the shell.
        executable_shell: Path to the shell to use if `shell` is True. Defaults to system default (usually /bin/sh).

    Returns:
        A tuple containing:
            - exit_code (int): The exit code of the command. -1 if execution failed.
            - stdout (str): The standard output of the command.
            - stderr (str): The standard error of the command.
    """
    logger.info(f"Executing command in {cwd}: {command}")
    if shell and executable_shell:
        logger.info(f"Using shell: {executable_shell}")
    try:
        # If shell is False, command should ideally be a list.
        # subprocess.run handles string command as program name if shell=False.
        # For simplicity, if shell=False and command is a string, it's split.
        # If shell=True, command is passed as a string to the shell.
        cmd_to_run = command if shell else command.split()
        process = subprocess.run(
            cmd_to_run,
            cwd=cwd,
            capture_output=True,
            text=True,  # Decodes stdout/stderr as text
            shell=shell,
            executable=(
                executable_shell if shell else None
            ),  # Specify the shell if provided
            check=False,  # Do not raise CalledProcessError, handle returncode manually
        )
        if process.returncode != 0:
            logger.warning(
                f"Command '{command}' failed with exit code {process.returncode} in {cwd}."
            )
            # Log output for failed commands to aid debugging.
            if process.stdout:
                logger.warning(f"Stdout from failed command:\n{process.stdout.strip()}")
            if process.stderr:
                logger.warning(f"Stderr from failed command:\n{process.stderr.strip()}")
        else:
            # Log output for successful commands at DEBUG level.
            if process.stdout:
                logger.debug(
                    f"Stdout from successful command:\n{process.stdout.strip()}"
                )
            if process.stderr:  # Some tools use stderr for informational messages.
                logger.debug(
                    f"Stderr from successful command:\n{process.stderr.strip()}"
                )
            logger.info(
                f"Command '{command}' finished successfully with exit code {process.returncode}."
            )
        return process.returncode, process.stdout, process.stderr
    except Exception as e:
        logger.error(f"Failed to execute command '{command}': {e}", exc_info=True)
        return -1, "", ""  # Ensure return path if body elided


def _create_summary_row(
    epoch: int,
    record_type: str,
    major_category: str,
    minor_category: str,
    sum_value: Optional[int],
    metric_fields_header: List[str],
) -> Dict[str, Any]:
    """Helper to create a common structure for summary rows in Parquet data."""
    row: Dict[str, Any] = {
        "Timestamp_epoch": epoch,
        "Record_Type": record_type,
        "Major_Category": major_category,
        "Minor_Category": minor_category,
        "PID": None,  # Summary rows don't have a specific PID
        "Command_Name": None,
        "Full_Command": None,
        "Sum_Value": sum_value,
    }
    for metric_name in metric_fields_header:
        # For PROCESS rows, actual metrics are filled.
        # For CATEGORY_SUM and ALL_SUM, individual metrics are None, only Sum_Value is primary.
        row[metric_name] = None
    return row


@dataclass
class MonitoringResults:
    """Holds the results from a monitoring loop."""

    all_samples_data: List[Dict[str, Any]]
    category_stats: Dict[str, Dict[str, Any]]
    peak_overall_memory_kb: int
    peak_overall_memory_epoch: int
    category_peak_sum: Dict[str, int]
    category_pid_set: Dict[str, set]


def _perform_monitoring_loop(
    active_memory_collector: AbstractMemoryCollector,
    current_build_proc: Optional[subprocess.Popen],
    project_name: str,
    parallelism_level: int,
    metric_fields_header: List[str],
    primary_metric_to_track: Optional[str],
) -> MonitoringResults:
    """
    Performs the main memory monitoring loop, collecting and processing samples.
    """
    all_samples_data_loop: List[Dict[str, Any]] = []
    category_stats_loop: Dict[str, Dict[str, Any]] = {}
    peak_overall_memory_kb_loop: int = 0
    peak_overall_memory_epoch_loop: int = 0
    category_peak_sum_loop: Dict[str, int] = {}
    category_pid_set_loop: Dict[str, set] = {}

    logger.info(f"Starting monitoring loop for {project_name} j{parallelism_level}...")

    for samples_at_interval in active_memory_collector.read_samples():
        current_epoch = int(time.time())
        category_mem_sum_interval: Dict[Tuple[str, str], int] = {}
        all_mem_sum_interval: int = 0
        category_pids_interval: Dict[Tuple[str, str], set] = {}

        for sample in samples_at_interval:
            major_cat, minor_cat = get_process_category(
                sample.command_name, sample.full_command
            )
            category_tuple = (major_cat, minor_cat)

            if major_cat == "Ignored":
                continue

            process_row_dict: Dict[str, Any] = {
                "Timestamp_epoch": current_epoch,
                "Record_Type": "PROCESS",
                "Major_Category": major_cat,
                "Minor_Category": minor_cat,
                "PID": sample.pid,
                "Command_Name": sample.command_name,
                "Full_Command": sample.full_command,
                "Sum_Value": None,  # Sum_Value is for summary rows
            }
            metric_value_for_sum = 0
            for metric_name in metric_fields_header:
                metric_val = sample.metrics.get(metric_name)
                try:
                    process_row_dict[metric_name] = (
                        int(metric_val) if metric_val is not None else None
                    )
                    if (
                        metric_name == primary_metric_to_track
                        and metric_val is not None
                    ):
                        metric_value_for_sum = int(metric_val)
                except (ValueError, TypeError):
                    process_row_dict[metric_name] = None
                    if metric_name == primary_metric_to_track:
                        logger.warning(
                            f"Could not convert primary metric '{metric_name}' value '{metric_val}' to int for PID {sample.pid}. Defaulting to 0 for sum."
                        )
            all_samples_data_loop.append(process_row_dict)

            all_mem_sum_interval += metric_value_for_sum
            category_mem_sum_interval.setdefault(category_tuple, 0)
            category_mem_sum_interval[category_tuple] += metric_value_for_sum
            category_pids_interval.setdefault(category_tuple, set()).add(sample.pid)

            if primary_metric_to_track:
                if (
                    category_tuple not in category_stats_loop
                    or metric_value_for_sum
                    > category_stats_loop[category_tuple].get(
                        "peak_metric", float("-inf")
                    )
                ):
                    category_stats_loop[category_tuple] = {
                        "peak_metric": metric_value_for_sum,
                        "pid": sample.pid,
                        "command": sample.command_name,
                        "full_command": sample.full_command,
                    }

        if all_mem_sum_interval > peak_overall_memory_kb_loop:
            peak_overall_memory_kb_loop = all_mem_sum_interval
            peak_overall_memory_epoch_loop = current_epoch

        for cat_tuple_sum, mem_sum_val_sum in category_mem_sum_interval.items():
            # Use the new helper for CATEGORY_SUM rows
            cat_sum_row_dict = _create_summary_row(
                current_epoch,
                "CATEGORY_SUM",
                cat_tuple_sum[0],
                cat_tuple_sum[1],
                mem_sum_val_sum,
                metric_fields_header,
            )
            all_samples_data_loop.append(cat_sum_row_dict)

        if primary_metric_to_track:
            # Use the new helper for ALL_SUM row
            all_sum_row_dict = _create_summary_row(
                current_epoch,
                "ALL_SUM",
                "ALL",
                "ALL",
                all_mem_sum_interval,
                metric_fields_header,
            )
            all_samples_data_loop.append(all_sum_row_dict)

        for cat, current_cat_sum in category_mem_sum_interval.items():
            category_peak_sum_loop[cat] = max(
                category_peak_sum_loop.get(cat, 0), current_cat_sum
            )

        for cat, pids_in_interval in category_pids_interval.items():
            category_pid_set_loop.setdefault(cat, set()).update(pids_in_interval)

        if current_build_proc and current_build_proc.poll() is not None:
            logger.info(
                f"Build process for {project_name} j{parallelism_level} finished. Stopping memory collection."
            )
            break

    logger.info(f"Monitoring loop for {project_name} j{parallelism_level} finished.")
    return MonitoringResults(
        all_samples_data=all_samples_data_loop,
        category_stats=category_stats_loop,
        peak_overall_memory_kb=peak_overall_memory_kb_loop,
        peak_overall_memory_epoch=peak_overall_memory_epoch_loop,
        category_peak_sum=category_peak_sum_loop,
        category_pid_set=category_pid_set_loop,
    )


def _prepare_initial_summary_log_header(
    project_name: str,
    parallelism_level: int,
    collector_type: str,
    project_dir: Path,
    actual_build_command: str,
    process_pattern: str,
    monitoring_interval: int,
    current_timestamp_str: str,
    output_parquet_file: Path,
    output_summary_log_file: Path,
    collector_aux_log_file: Path,
    monitor_script_pinned_to_core_info: str,
    build_cores_target_str: str,
    monitor_core_id_for_collector_and_build_avoidance: Optional[int],
    taskset_available: bool,
) -> List[str]:
    """Prepares the header content for the summary log file."""
    header_content: List[str] = []
    header_content.append("=" * 80)
    header_content.append(f"Project: {project_name}")
    header_content.append(f"Parallelism: -j{parallelism_level}")
    header_content.append(f"Memory Metric Collector: {collector_type.upper()}")
    header_content.append(f"Source Directory: {project_dir.resolve()}")
    header_content.append(f"Actual Build Command: {actual_build_command}")
    header_content.append(f"Process Pattern (for collector): {process_pattern}")
    header_content.append(
        f"Monitoring Interval (approx): {monitoring_interval} seconds"
    )
    header_content.append(
        f"Run Timestamp: {current_timestamp_str} ({time.strftime('%Y-%m-%d %H:%M:%S')})"
    )
    header_content.append(f"Output Parquet File: {output_parquet_file.name}")
    header_content.append(f"Summary Log File: {output_summary_log_file.name}")
    if collector_type == "rss_pidstat":
        header_content.append(
            f"Collector Aux Log (temporary, will be merged): {collector_aux_log_file.name}"
        )
    header_content.append(
        f"Monitor Script Pinned to CPU Core: {monitor_script_pinned_to_core_info}"
    )
    header_content.append(f"Build Processes CPU Cores Target: {build_cores_target_str}")
    if (
        collector_type == "rss_pidstat"
        and monitor_core_id_for_collector_and_build_avoidance is not None
        and taskset_available
    ):
        header_content.append(
            f"Pidstat Collector Target CPU Core: {monitor_core_id_for_collector_and_build_avoidance} (via taskset)"
        )
    elif collector_type == "rss_pidstat":
        header_content.append(
            f"Pidstat Collector Target CPU Core: Not Pinned (monitor_core_id not set or taskset unavailable)"
        )
    header_content.append("-" * 80)
    return header_content


def _compile_and_write_final_summary_and_aux_logs(
    summary_file_path: Path,
    build_exit_code: int,
    duration_float: float,
    duration_formatted: str,
    primary_metric: Optional[str],
    results: MonitoringResults,
    collector_type_str: str,
    aux_log_file_path: Path,
) -> None:
    """Compiles the final summary statistics and writes them to the log file and console."""
    final_summary_log_lines: List[str] = []
    final_summary_log_lines.append("\n--- Build & Monitoring Summary ---")
    final_summary_log_lines.append(
        f"Total Build & Monitoring Duration: {duration_formatted} ({duration_float:.2f} seconds)"
    )
    final_summary_log_lines.append(f"Final Build Exit Code: {build_exit_code}")

    if primary_metric:
        peak_time_str = (
            time.strftime(
                "%Y-%m-%d %H:%M:%S", time.localtime(results.peak_overall_memory_epoch)
            )
            if results.peak_overall_memory_epoch > 0
            else "N/A (no peak recorded or build did not run long enough)"
        )
        final_summary_log_lines.append(
            f"Peak Overall Memory ({primary_metric}): {results.peak_overall_memory_kb} KB (at approx. {peak_time_str})"
        )
    else:
        final_summary_log_lines.append(
            f"Peak Overall Memory: N/A (no primary metric was tracked for sum)"
        )

    final_summary_log_lines.append(
        f"Peak Single Process Memory Usage (by category, based on {primary_metric or 'N/A'}):"
    )
    if results.category_stats:
        for category, stats in sorted(results.category_stats.items()):
            peak_val = stats.get("peak_metric", "N/A")
            pid_val = stats.get("pid", "N/A")
            cmd_val = stats.get("command", "N/A")
            full_cmd_val = stats.get("full_command", "N/A")
            final_summary_log_lines.append(
                f"  - {category}: {peak_val} KB (PID: {pid_val}, Command: {cmd_val})"
            )
            final_summary_log_lines.append(f"    Full Command: {full_cmd_val}")
    else:
        final_summary_log_lines.append(
            "  No category-specific single process peak memory data collected."
        )

    final_summary_log_lines.append(
        f"Peak Category Sum Memory Usage (sum of processes in category, based on {primary_metric or 'N/A'}):"
    )
    if results.category_peak_sum:
        for category, peak_sum_val in sorted(results.category_peak_sum.items()):
            final_summary_log_lines.append(f"  - {category}: {peak_sum_val} KB")
    else:
        final_summary_log_lines.append("  No category sum peak memory data collected.")

    final_summary_log_lines.append("Unique Process Counts (by category):")
    if results.category_pid_set:
        for category, pids in sorted(results.category_pid_set.items()):
            final_summary_log_lines.append(
                f"  - {category}: {len(pids)} unique process(es)"
            )
    else:
        final_summary_log_lines.append("  No unique process count data collected.")

    final_summary_log_lines.append("--- End Summary ---")

    # must be within the same file handle scope to write to the same file.
    with open(summary_file_path, "a") as f_summary:
        f_summary.write("\n")  # Ensure a blank line before summary sections

        # Merge collector auxiliary log first, if applicable
        if (
            collector_type_str == "rss_pidstat"
            and aux_log_file_path.exists()
            and aux_log_file_path.stat().st_size > 0
        ):
            f_summary.write("\n--- Collector Auxiliary Log Output ---\n")
            try:
                with open(aux_log_file_path, "r") as f_aux:
                    f_summary.write(f_aux.read())
                f_summary.write("--- End Collector Auxiliary Log Output ---\n\n")
                try:
                    aux_log_file_path.unlink()
                    logger.info(
                        f"Merged and deleted collector aux log: {aux_log_file_path.name}"
                    )
                except OSError as e_del:
                    logger.warning(
                        f"Could not delete collector aux log {aux_log_file_path.name}: {e_del}"
                    )
            except Exception as e_read_aux:
                error_msg_aux = f"Error reading collector aux log {aux_log_file_path.name}: {e_read_aux}"
                f_summary.write(f"{error_msg_aux}\n")
                logger.error(error_msg_aux)

        # Now, write the compiled final summary lines to the file
        for line in final_summary_log_lines:
            f_summary.write(line + "\n")

    # Log the summary to the console as well
    for line in final_summary_log_lines:
        logger.info(line)


def _write_monitoring_data_to_parquet(
    all_samples_data: List[Dict[str, Any]],
    output_parquet_file: Path,
    project_name: str,  # For logging context
    parallelism_level: int,  # For logging context
) -> None:
    """Writes the collected monitoring data to a Parquet file."""
    df_to_save: Optional[pl.DataFrame] = None
    if not all_samples_data:
        logger.info(
            f"No data collected to write to Parquet file for {project_name} j{parallelism_level}."
        )
        df_to_save = pl.DataFrame([])
    else:
        if not all(isinstance(item, dict) for item in all_samples_data):
            logger.error(
                "Not all items in all_samples_data are dictionaries. This will cause DataFrame creation to fail."
            )
            problematic_items_logged = 0
            for i, item in enumerate(all_samples_data):
                if not isinstance(item, dict):
                    logger.error(
                        f"  Item at index {i} is not a dict: Type {type(item)}, Content (first 100 chars): {str(item)[:100]}"
                    )
                    problematic_items_logged += 1
                    if problematic_items_logged >= 5:
                        break
        try:
            df_to_save = pl.DataFrame(all_samples_data)
        except Exception as e_df_create:
            logger.error(
                f"Failed to create DataFrame from all_samples_data: {e_df_create}",
                exc_info=True,
            )
            df_to_save = None

    if df_to_save is not None:
        try:
            output_parquet_file.parent.mkdir(parents=True, exist_ok=True)
            df_to_save.write_parquet(output_parquet_file)
            if not output_parquet_file.exists():
                logger.error(
                    f"Parquet file {output_parquet_file.resolve()} was NOT created after write_parquet call!"
                )
        except Exception as e_write:
            logger.error(
                f"Exception during Parquet write_parquet call for {output_parquet_file.resolve()}: {e_write}",
                exc_info=True,
            )
    else:
        logger.error(
            "DataFrame for Parquet was not created (likely due to previous errors), skipping Parquet write."
        )


# --- NEW OR MOVED HELPER FUNCTIONS ---


@dataclass
class RunPaths:
    """Holds paths for a single monitoring run."""

    output_parquet_file: Path
    output_summary_log_file: Path
    collector_aux_log_file: Path


def _generate_run_paths(
    log_dir: Path,
    project_name: str,
    parallelism_level: int,
    collector_type: str,
    current_timestamp_str: str,
) -> RunPaths:
    """Generates all necessary output paths for a monitoring run."""
    base_filename_part = f"{project_name}_j{parallelism_level}_mem_{collector_type}_{current_timestamp_str}"
    output_parquet_filename = f"{base_filename_part}.parquet"
    output_summary_log_filename = f"{base_filename_part}_summary.log"

    return RunPaths(
        output_parquet_file=log_dir / output_parquet_filename,
        output_summary_log_file=log_dir / output_summary_log_filename,
        collector_aux_log_file=log_dir / f"{base_filename_part}_collector_aux.log",
    )


def _create_memory_collector(
    collector_type: str,
    process_pattern: str,
    monitoring_interval: int,
    collector_aux_log_file: Path,  # Specific to RssPidstatCollector
    monitor_core_id: Optional[int],  # Specific to RssPidstatCollector
    taskset_available: bool,  # Specific to RssPidstatCollector
) -> Optional[AbstractMemoryCollector]:
    """Creates and returns a memory collector instance."""
    global active_memory_collector  # To assign to the global for cleanup

    collector_kwargs: Dict[str, Any] = {}
    if collector_type == "rss_pidstat":
        collector_kwargs["pidstat_stderr_file"] = collector_aux_log_file
        collector_kwargs["collector_cpu_core"] = monitor_core_id
        collector_kwargs["taskset_available"] = taskset_available
        active_memory_collector = RssPidstatCollector(
            process_pattern, monitoring_interval, **collector_kwargs
        )
    elif collector_type == "pss_psutil":
        # PssPsutilCollector currently doesn't use these specific kwargs,
        # but we pass them in case its __init__ is extended.
        collector_kwargs["collector_cpu_core"] = monitor_core_id
        collector_kwargs["taskset_available"] = taskset_available
        active_memory_collector = PssPsutilCollector(
            process_pattern, monitoring_interval, **collector_kwargs
        )
    else:
        logger.error(f"Unsupported collector type: {collector_type}.")
        return None
    return active_memory_collector


def _run_and_log_command_to_summary(  # MOVED to top-level private function
    cmd_str: str,
    cmd_desc: str,
    cwd_path: Path,
    shell_bool: bool,
    summary_file: Path,
    executable_shell: Optional[str] = None,
) -> int:
    """Runs a command and logs its execution details to the summary file."""
    logger.info(f"Executing {cmd_desc} command: {cmd_str} in {cwd_path}")
    if shell_bool and executable_shell:
        logger.info(f"Using shell for {cmd_desc}: {executable_shell}")
    with open(summary_file, "a") as f_s:
        f_s.write(f"\n--- {cmd_desc} Command ---\n")
        f_s.write(f"Command: {cmd_str}\n")
        f_s.write(f"Directory: {cwd_path}\n")
        f_s.write(f"Execution Time: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")

    exit_code, stdout_val, stderr_val = run_command(
        cmd_str,
        cwd=cwd_path,
        shell=shell_bool,
        executable_shell=executable_shell,
    )

    with open(summary_file, "a") as f_s:
        f_s.write(f"Exit Code: {exit_code}\n")
        if stdout_val:
            f_s.write(f"Stdout:\n{stdout_val.strip()}\n")
        if stderr_val:
            f_s.write(f"Stderr:\n{stderr_val.strip()}\n")
        f_s.write(f"--- End {cmd_desc} Command ---\n\n")

    if exit_code != 0:
        logger.warning(
            f"{cmd_desc} command failed with exit code {exit_code}. Continuing build process..."
        )
    else:
        logger.info(f"{cmd_desc} command completed successfully.")
    return exit_code


def _execute_clean_step(
    setup_cmd_template: str,
    clean_cmd_template: str,
    project_dir: Path,
    summary_file: Path,
    description: str,
) -> None:
    """
    Prepares and executes a clean command, logging the process to the summary file.

    This helper encapsulates the logic for both pre-build and post-build clean steps.

    Args:
        setup_cmd_template: The setup command template, if any.
        clean_cmd_template: The clean command template.
        project_dir: The directory where the command should be run.
        summary_file: The path to the summary log file.
        description: A description of the step (e.g., "Pre-Build Clean").
    """
    if not clean_cmd_template:
        logger.info(f"No clean command defined, skipping '{description}'.")
        return

    actual_clean_cmd, executable_shell = _prepare_actual_clean_command(
        setup_cmd_template, clean_cmd_template
    )
    _run_and_log_command_to_summary(
        actual_clean_cmd,
        description,
        project_dir,
        True,  # shell=True for clean commands
        summary_file,
        executable_shell=executable_shell,
    )


# --- END NEW OR MOVED HELPER FUNCTIONS ---


def run_and_monitor_build(
    project_config: Dict[str, Any],
    parallelism_level: int,
    monitoring_interval: int,
    log_dir: Path,
    collector_type: str = "pss_psutil",
    monitor_core_id_for_collector_and_build_avoidance: Optional[int] = None,
    build_cpu_cores_policy: str = "all_others",
    specific_build_cores_str: Optional[str] = None,
    monitor_script_pinned_to_core_info: str = "Not Pinned",
) -> None:
    global current_build_proc  # Removed active_memory_collector, handled by _create_memory_collector

    project_name = project_config["NAME"]
    project_dir = Path(project_config["DIR"])
    build_command_template = project_config["BUILD_COMMAND_TEMPLATE"]
    process_pattern = project_config["PROCESS_PATTERN"]
    clean_command_template = project_config.get("CLEAN_COMMAND_TEMPLATE", "")
    setup_command_template = project_config.get("SETUP_COMMAND_TEMPLATE", "")

    current_timestamp_str = time.strftime("%Y%m%d_%H%M%S")

    run_paths = _generate_run_paths(
        log_dir, project_name, parallelism_level, collector_type, current_timestamp_str
    )
    output_parquet_file = run_paths.output_parquet_file
    output_summary_log_file = run_paths.output_summary_log_file
    # collector_aux_log_file is part of run_paths and passed to _create_memory_collector

    base_build_cmd = build_command_template.replace("<N>", str(parallelism_level))
    if setup_command_template:
        actual_build_command = f"{setup_command_template} && {base_build_cmd}"
    else:
        actual_build_command = base_build_cmd

    # This variable was used below but never defined, causing a NameError.
    # It should be assigned the base_build_cmd, as this is the core command
    # that will be executed by Popen with shell=False.
    full_build_command_for_popen = base_build_cmd

    taskset_available = False
    try:
        # ... (existing taskset check) ...
        taskset_check_process = subprocess.run(
            ["which", "taskset"], capture_output=True, text=True, check=False
        )
        taskset_available = taskset_check_process.returncode == 0
    except Exception as e_taskset:
        logger.warning(
            f"Error checking for taskset: {e_taskset}. Assuming not available."
        )

    num_total_cores = psutil.cpu_count()

    build_command_prefix, build_cores_target_str = _determine_build_cpu_affinity(
        # ... (pass arguments) ...
        build_cpu_cores_policy,
        specific_build_cores_str,
        monitor_core_id_for_collector_and_build_avoidance,
        taskset_available,
        num_total_cores,
    )

    summary_log_header_content = _prepare_initial_summary_log_header(
        # ... (pass arguments, including run_paths.collector_aux_log_file) ...
        project_name,
        parallelism_level,
        collector_type,
        project_dir,
        actual_build_command,
        process_pattern,
        monitoring_interval,
        current_timestamp_str,
        output_parquet_file,
        output_summary_log_file,
        run_paths.collector_aux_log_file,  # Use path from RunPaths
        monitor_script_pinned_to_core_info,
        build_cores_target_str,
        monitor_core_id_for_collector_and_build_avoidance,
        taskset_available,
    )

    for line in summary_log_header_content:
        logger.info(line.replace("=", "-"))
    with open(output_summary_log_file, "w") as f_summary:
        for line in summary_log_header_content:
            f_summary.write(line + "\n")
        f_summary.write("\n")

    if not project_dir.is_dir():
        # ... (existing project_dir check logic) ...
        return

    local_active_memory_collector = (
        _create_memory_collector(  # Assign to local var first
            collector_type,
            process_pattern,
            monitoring_interval,
            run_paths.collector_aux_log_file,  # Pass aux file path
            monitor_core_id_for_collector_and_build_avoidance,
            taskset_available,
        )
    )
    if not local_active_memory_collector:  # Check if collector creation failed
        error_msg = f"Failed to create memory collector of type {collector_type}."
        logger.error(error_msg)
        with open(output_summary_log_file, "a") as f_summary:
            f_summary.write(f"ERROR: {error_msg}\n")
        return
    # active_memory_collector global is set inside _create_memory_collector

    # Pre-build clean command (uses the new helper)
    _execute_clean_step(
        setup_command_template,
        clean_command_template,
        project_dir,
        output_summary_log_file,
        "Pre-Build Clean",
    )

    # --- Build Monitoring ---
    # REMOVED initialization of category_stats, peak_overall_memory_kb, etc.
    build_stdout_lines: List[str] = []
    build_stderr_lines: List[str] = []

    build_exit_code: int = -1
    start_time_seconds: Optional[float] = None
    stdout_thread: Optional[threading.Thread] = None
    stderr_thread: Optional[threading.Thread] = None

    # FIX: Initialize variables to None before the try block.
    # This prevents a NameError in the finally block if an exception occurs
    # before these variables are assigned.
    monitoring_results: Optional[MonitoringResults] = None
    primary_metric_to_track: Optional[str] = None

    try:
        # This metric is determined after the collector is created, so it's safe to define here.
        metric_fields_header = local_active_memory_collector.get_metric_fields()
        primary_metric_to_track = (
            metric_fields_header[0] if metric_fields_header else None
        )

        local_active_memory_collector.start()  # Use local variable

        # FIX 2: Correctly construct the command list for Popen.
        # The original code used `[build_command_prefix]`, which created an incorrect
        # list element like ['taskset -c 1-7 ']. Using .split() correctly
        # separates the command and its arguments.
        cmd_list_for_popen = (
            build_command_prefix.split() if build_command_prefix else []
        ) + full_build_command_for_popen.split()

        with open(output_summary_log_file, "a") as f_summary:
            f_summary.write("--- Build Command Execution ---\n")
            # Log the actual command list that will be executed for accuracy.
            f_summary.write(f"Command: {' '.join(cmd_list_for_popen)}\n")
            f_summary.write(
                f"Execution Start Time: {time.strftime('%Y-%m-%d %H:%M:%S')}\n"
            )

        start_time_seconds = time.monotonic()

        current_build_proc = subprocess.Popen(
            cmd_list_for_popen,
            cwd=project_dir,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            shell=False,
            bufsize=1,
        )

        stdout_thread = _start_stream_reader_thread(
            current_build_proc.stdout,
            "STDOUT",
            project_name,
            parallelism_level,
            build_stdout_lines,
        )
        stderr_thread = _start_stream_reader_thread(
            current_build_proc.stderr,
            "STDERR",
            project_name,
            parallelism_level,
            build_stderr_lines,
        )

        monitoring_results = _perform_monitoring_loop(
            local_active_memory_collector,  # Use local variable
            current_build_proc,
            project_name,
            parallelism_level,
            metric_fields_header,
            primary_metric_to_track,
        )

        if current_build_proc:
            build_exit_code = current_build_proc.wait()
            logger.info(
                f"Build process for {project_name} j{parallelism_level} exited with code: {build_exit_code}."
            )
            with open(output_summary_log_file, "a") as f_summary:
                f_summary.write(
                    f"Build End Time: {time.strftime('%Y-%m-%d %H:%M:%S')}\n"
                )
                f_summary.write(f"Build Exit Code: {build_exit_code}\n")
                if stdout_thread and stdout_thread.is_alive():
                    stdout_thread.join(timeout=1)
                if stderr_thread and stderr_thread.is_alive():
                    stderr_thread.join(timeout=1)

                _write_stream_to_summary(f_summary, "STDOUT", build_stdout_lines)
                _write_stream_to_summary(f_summary, "STDERR", build_stderr_lines)

                f_summary.write(f"--- End Build Command Execution ---\n\n")

        if stdout_thread and stdout_thread.is_alive():
            stdout_thread.join(timeout=5)
        if stderr_thread and stderr_thread.is_alive():
            stderr_thread.join(timeout=5)
        logger.info(
            f"Build process stdout/stderr streaming for {project_name} j{parallelism_level} finished."
        )

    except Exception as e:
        # ... (existing exception handling) ...
        error_msg = f"An critical error occurred during monitoring for {project_name} j{parallelism_level}: {e}"
        logger.error(error_msg, exc_info=True)
        with open(output_summary_log_file, "a") as f_summary:
            f_summary.write(
                f"\nCRITICAL ERROR DURING MONITORING:\n{error_msg}\nDetails: {str(e)}\n"
            )
        if current_build_proc and current_build_proc.poll() is None:
            build_exit_code = current_build_proc.wait()

    finally:
        # The global active_memory_collector is used by cleanup_processes signal handler.
        # It's set by _create_memory_collector. We stop it here.
        if local_active_memory_collector:
            logger.info(
                f"Stopping memory collector ({local_active_memory_collector.__class__.__name__}) for {project_name} j{parallelism_level}."
            )
            local_active_memory_collector.stop()
            # The signal handler also sets the global active_memory_collector to None.

        if current_build_proc and current_build_proc.poll() is None:
            logger.warning(
                f"Build process {current_build_proc.pid} for {project_name} j{parallelism_level} still running in finally block. Attempting to terminate."
            )
            current_build_proc.terminate()
            try:
                current_build_proc.wait(timeout=10)
            except subprocess.TimeoutExpired:
                logger.error(
                    f"Build process {current_build_proc.pid} did not terminate. Killing."
                )
                current_build_proc.kill()
            current_build_proc = None

        end_time_seconds = time.time()
        duration_seconds_float = (
            (end_time_seconds - start_time_seconds)
            if start_time_seconds is not None
            else 0
        )
        duration_seconds = int(duration_seconds_float)
        h, m, s = (
            duration_seconds // 3600,
            (duration_seconds % 3600) // 60,
            duration_seconds % 60,
        )
        formatted_duration = f"{h:02d}:{m:02d}:{s:02d}"

        # Check if monitoring_results exists before trying to use it.
        if monitoring_results:
            _compile_and_write_final_summary_and_aux_logs(
                output_summary_log_file,
                build_exit_code,
                duration_seconds_float,
                formatted_duration,
                primary_metric_to_track,
                monitoring_results,  # Pass the single results object
                collector_type,
                run_paths.collector_aux_log_file,  # Use path from RunPaths
            )

            _write_monitoring_data_to_parquet(
                monitoring_results.all_samples_data,  # Get data from the results object
                output_parquet_file,
                project_name,
                parallelism_level,
            )

            logger.info(
                f"Monitoring for {project_name} j{parallelism_level} ({collector_type}) finished successfully."
            )
        else:
            logger.error(
                f"No monitoring results were generated for {project_name} j{parallelism_level}, likely due to an earlier error. Final summary and parquet file will be incomplete."
            )

        # FIX: The post-build clean step should run regardless of whether monitoring
        # results were successfully generated. It is part of the cleanup process
        # that the 'finally' block is intended to guarantee.
        # It is moved out of the 'if monitoring_results:' block to run unconditionally.
        _execute_clean_step(
            setup_command_template,
            clean_command_template,
            project_dir,
            output_summary_log_file,
            "Post-Build Clean",
        )


def cleanup_processes() -> None:
    """
    Cleans up any running global subprocesses (build process, memory collector).

    This function is intended to be called by a signal handler (e.g., SIGINT, SIGTERM)
    to ensure graceful shutdown of child processes.
    """
    logger.info(
        "Signal received: Cleaning up any running subprocesses and collectors..."
    )
    global current_build_proc, active_memory_collector

    if active_memory_collector:
        logger.info(
            f"Stopping active memory collector ({active_memory_collector.__class__.__name__}) from cleanup handler."
        )
        active_memory_collector.stop()
        active_memory_collector = None  # Reset global variable

    if (
        current_build_proc and current_build_proc.poll() is None
    ):  # Check if process is still running
        logger.info(
            f"Terminating build process (PID {current_build_proc.pid}) from cleanup handler."
        )
        current_build_proc.terminate()  # Send SIGTERM
        try:
            current_build_proc.wait(timeout=10)  # Wait for graceful termination
            logger.info(f"Build process (PID {current_build_proc.pid}) terminated.")
        except subprocess.TimeoutExpired:
            logger.error(
                f"Build process {current_build_proc.pid} did not terminate in cleanup, killing."
            )
            current_build_proc.kill()  # Send SIGKILL if terminate fails
        current_build_proc = None  # Reset global variable
    logger.info("Cleanup finished.")


def check_pidstat_installed() -> bool:
    """
    Checks if the 'pidstat' command is installed and available in the system PATH.

    Returns:
        True if pidstat is installed, False otherwise.
    """
    try:
        # Running 'pidstat -V' typically prints version information.
        # capture_output=True suppresses output to console.
        # check=True will raise CalledProcessError if pidstat returns non-zero.
        subprocess.run(["pidstat", "-V"], capture_output=True, check=True)
        return True
    except (subprocess.CalledProcessError, FileNotFoundError):
        # FileNotFoundError if 'pidstat' command doesn't exist.
        # CalledProcessError if 'pidstat -V' fails for some reason.
        return False
